# Lunar Lander with Reinforcement Learning

## Soft-Actor Critic (SAC)

![](/Images/sac_lunar_lander.gif)

## Deep Q Learning (DQN)

![](/Images/dqn_lunar_lander.gif)

## Proximal Policy Optimization (PPO)

![](/Images/ppo_lunar_lander.gif)

## Results
Hardware: Google Colab T4

| Model Type | Discrete | Average Reward| Training Time | Total Training Steps |
|------------|----------|---------------|---------------|----------------------|
| PPO        | No       | 179.83        | 1:28:36       | 300,000              |
| SAC        | No       | 257.90        | 1:36:07       | 179,285              |
| DQN        | Yes      |               |               |                      |

## Finding Theta Blog Posts: 
- [Solving Gymnasium's Lunar Lander with Deep Q Learning (DQN)](https://www.findingtheta.com/blog/solving-gymnasiums-lunar-lander-with-deep-q-learning-dqn)
- [Comparing how PPO, SAC, and DQN Perform on Gymnasium's Lunar Lander](https://www.findingtheta.com/blog/comparing-how-ppo-sac-and-dqn-perform-on-gymnasiums-lunar-lander)
