{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS90f-pm5nV9"
      },
      "source": [
        "# Deep Q-Network (DQN)\n",
        "---\n",
        "In this notebook, you will implement a DQN agent with OpenAI Gym's LunarLander-v2 environment.\n",
        "\n",
        "### 1. Import the Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8cD0fYr5sVm",
        "outputId": "0927f9e7-6eb5-49e7-f7d2-0b8386335a3e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium gymnasium[box2d] stable_baselines3 shimmmy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLnLyxAJ6saY",
        "outputId": "c061cab9-b7cd-4fe1-92b7-c07439e5a741"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement shimmmy (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for shimmmy\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aZ1YZWDq5nV-"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    \"\"\"Actor (Policy) Model.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed, fc1_units=128, fc2_units=128):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            seed (int): Random seed\n",
        "            fc1_units (int): Number of nodes in first hidden layer\n",
        "            fc2_units (int): Number of nodes in second hidden layer\n",
        "        \"\"\"\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
        "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
        "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
        "\n",
        "    def forward(self, state):\n",
        "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "8AQGk5RP81a-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import namedtuple, deque\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
        "BATCH_SIZE = 64         # minibatch size\n",
        "GAMMA = 0.99            # discount factor\n",
        "TAU = 1e-3              # for soft update of target parameters\n",
        "LR = 5e-4               # learning rate\n",
        "UPDATE_EVERY = 4        # how often to update the network\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            action_size (int): dimension of each action\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
        "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "        self.t_step = 0\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > BATCH_SIZE:\n",
        "                experiences = self.memory.sample()\n",
        "                self.learn(experiences, GAMMA)\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        \"\"\"Returns actions for given state as per current policy.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state (array_like): current state\n",
        "            eps (float): epsilon, for epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples\n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Get max predicted Q values (for next states) from target model\n",
        "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        # Compute Q targets for current states\n",
        "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
        "\n",
        "        # Get expected Q values from local model\n",
        "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        # Minimize the loss\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # ------------------- update target network ------------------- #\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)\n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            local_model (PyTorch model): weights will be copied from\n",
        "            target_model (PyTorch model): weights will be copied to\n",
        "            tau (float): interpolation parameter\n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            action_size (int): dimension of each action\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            batch_size (int): size of each training batch\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "ANgyqOQA8yVm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8ps4GLm5nV-"
      },
      "source": [
        "### 2. Instantiate the Environment and Agent\n",
        "\n",
        "Initialize the environment in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O8Hk6tG5nV-",
        "outputId": "9ec0c1eb-be78-4ade-b832-7bd398c5b30a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State shape:  (8,)\n",
            "Number of actions:  4\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('LunarLander-v2',render_mode='human')\n",
        "print('State shape: ', env.observation_space.shape)\n",
        "print('Number of actions: ', env.action_space.n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n97od6Ll5nV_"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "for step in range(200):\n",
        "    env.render()\n",
        "    action = env.action_space.sample() # cart accelerates to the right\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    if terminated or truncated:\n",
        "        env.reset()\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUABGGyA5nV_"
      },
      "source": [
        "Please refer to the instructions in `Deep_Q_Network.ipynb` if you would like to write your own DQN agent.  Otherwise, run the code cell below to load the solution files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlYEpVzh5nV_"
      },
      "source": [
        "### 3. Train the Agent with DQN\n",
        "\n",
        "Run the code cell below to train the agent from scratch.  You are welcome to amend the supplied values of the parameters in the function, to try to see if you can get better performance!\n",
        "\n",
        "Alternatively, you can skip to the next step below (**4. Watch a Smart Agent!**), to load the saved model weights from a pre-trained agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J0fXrJOx5nV_"
      },
      "outputs": [],
      "source": [
        "env = gym.make('LunarLander-v2')\n",
        "agent = Agent(state_size=8, action_size=4, seed=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "Vn1axrI35nV_",
        "outputId": "e952f1e2-354c-46d7-87a7-d4ba8686d609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100\tAverage Score: -148.97\n",
            "Episode 200\tAverage Score: -118.37\n",
            "Episode 300\tAverage Score: -92.10\n",
            "Episode 400\tAverage Score: -29.02\n",
            "Episode 500\tAverage Score: 22.66\n",
            "Episode 600\tAverage Score: 167.19\n",
            "Episode 700\tAverage Score: 213.86\n",
            "Episode 800\tAverage Score: 177.27\n",
            "Episode 900\tAverage Score: 195.51\n",
            "Episode 1000\tAverage Score: 214.93\n",
            "Episode 1100\tAverage Score: 249.85\n",
            "Episode 1200\tAverage Score: 255.69\n",
            "Episode 1300\tAverage Score: 252.56\n",
            "Episode 1400\tAverage Score: 247.45\n",
            "Episode 1473\tAverage Score: 260.06\n",
            "Environment solved in 1373 episodes!\tAverage Score: 260.06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
        "    \"\"\"Deep Q-Learning.\n",
        "\n",
        "    Params\n",
        "    ======\n",
        "        n_episodes (int): maximum number of training episodes\n",
        "        max_t (int): maximum number of timesteps per episode\n",
        "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
        "        eps_end (float): minimum value of epsilon\n",
        "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
        "    \"\"\"\n",
        "    scores = []                        # list containing scores from each episode\n",
        "    scores_window = deque(maxlen=100)  # last 100 scores\n",
        "    eps = eps_start                    # initialize epsilon\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        state,info = env.reset()\n",
        "        score = 0\n",
        "        for t in range(max_t):\n",
        "            action = agent.act(state, eps)\n",
        "            next_state, reward, done, info,_ = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            if done:\n",
        "                break\n",
        "        scores_window.append(score)       # save most recent score\n",
        "        scores.append(score)              # save most recent score\n",
        "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
        "        if i_episode % 100 == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
        "        if np.mean(scores_window)>=260.0:\n",
        "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
        "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint_lunar.pth')\n",
        "            break\n",
        "    return scores\n",
        "\n",
        "scores = dqn()\n",
        "\n",
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)), scores)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TUIujGd5nV_"
      },
      "source": [
        "### 4. Watch a Smart Agent!\n",
        "\n",
        "In the next code cell, you will load the trained weights from file to watch a smart agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru4IUM7w5nV_",
        "outputId": "667b1145-d956-4bfb-ee96-49673d3b5e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /content/video/rl-video-episode-0.mp4.\n",
            "Moviepy - Writing video /content/video/rl-video-episode-0.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/video/rl-video-episode-0.mp4\n",
            "Moviepy - Building video /content/video/rl-video-episode-1.mp4.\n",
            "Moviepy - Writing video /content/video/rl-video-episode-1.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/video/rl-video-episode-1.mp4\n",
            "Moviepy - Building video /content/video/rl-video-episode-2.mp4.\n",
            "Moviepy - Writing video /content/video/rl-video-episode-2.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/video/rl-video-episode-2.mp4\n"
          ]
        }
      ],
      "source": [
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "env = gym.make('LunarLander-v2',render_mode='rgb_array')\n",
        "\n",
        "# Wrap the environment to record video\n",
        "env = RecordVideo(env, video_folder='./video', episode_trigger=lambda e: True)\n",
        "\n",
        "agent.qnetwork_local.load_state_dict(torch.load('checkpoint_lunar.pth'))\n",
        "\n",
        "for i in range(3):\n",
        "    state,info = env.reset()\n",
        "    for j in range(400):\n",
        "        action = agent.act(state)\n",
        "        env.render()\n",
        "        #time.sleep(0.3)\n",
        "        state, reward, terminated, truncated, info= env.step(action)\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqWzNgQT5nWA"
      },
      "source": [
        "### 5. Explore\n",
        "\n",
        "In this exercise, you have implemented a DQN agent and demonstrated how to use it to solve an OpenAI Gym environment.  To continue your learning, you are encouraged to complete any (or all!) of the following tasks:\n",
        "- Amend the various hyperparameters and network architecture to see if you can get your agent to solve the environment faster.  Once you build intuition for the hyperparameters that work well with this environment, try solving a different OpenAI Gym task with discrete actions!\n",
        "- You may like to implement some improvements such as prioritized experience replay, Double DQN, or Dueling DQN!\n",
        "- Write a blog post explaining the intuition behind the DQN algorithm and demonstrating how to use it to solve an RL environment of your choosing.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium\n",
        "from stable_baselines3 import DQN\n",
        "\n",
        "# Create Lunar Lander environment\n",
        "env = gymnasium.make('LunarLander-v2')\n",
        "\n",
        "# Initialize DQN\n",
        "model = DQN('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=100000)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"dqn_lunar_lander\")"
      ],
      "metadata": {
        "id": "KiyIp2g3Nae-",
        "outputId": "17cbecbf-2aa5-4f81-c4d6-94409e190789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.96     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 341      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 422      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.693    |\n",
            "|    n_updates        | 80       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.2     |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.931    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 356      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 730      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.23     |\n",
            "|    n_updates        | 157      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.8     |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.898    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 384      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1077     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.05     |\n",
            "|    n_updates        | 244      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.1     |\n",
            "|    ep_rew_mean      | -166     |\n",
            "|    exploration_rate | 0.86     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 466      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 1474     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.931    |\n",
            "|    n_updates        | 343      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.8     |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.822    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 528      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 1875     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.19     |\n",
            "|    n_updates        | 443      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95.4     |\n",
            "|    ep_rew_mean      | -189     |\n",
            "|    exploration_rate | 0.782    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 582      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2290     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.92     |\n",
            "|    n_updates        | 547      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.727    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 638      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 2877     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.927    |\n",
            "|    n_updates        | 694      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.676    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 680      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 3408     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 826      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 111      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.621    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 711      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 3994     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.39     |\n",
            "|    n_updates        | 973      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 118      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.55     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 731      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 4732     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.29     |\n",
            "|    n_updates        | 1157     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 122      |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.489    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 733      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 5377     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.24     |\n",
            "|    n_updates        | 1319     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 126      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.425    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 6050     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 1487     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.35     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 731      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 6845     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.501    |\n",
            "|    n_updates        | 1686     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 162      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.139    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 758      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9063     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.26     |\n",
            "|    n_updates        | 2240     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 762      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 11399    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.6      |\n",
            "|    n_updates        | 2824     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 201      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 763      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 12886    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.802    |\n",
            "|    n_updates        | 3196     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -213     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 764      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 13584    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.97     |\n",
            "|    n_updates        | 3370     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 198      |\n",
            "|    ep_rew_mean      | -225     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 765      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 14247    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.31     |\n",
            "|    n_updates        | 3536     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 745      |\n",
            "|    time_elapsed     | 22       |\n",
            "|    total_timesteps  | 16750    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.6      |\n",
            "|    n_updates        | 4162     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 249      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 752      |\n",
            "|    time_elapsed     | 26       |\n",
            "|    total_timesteps  | 19903    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.72     |\n",
            "|    n_updates        | 4950     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 261      |\n",
            "|    ep_rew_mean      | -232     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 755      |\n",
            "|    time_elapsed     | 28       |\n",
            "|    total_timesteps  | 21899    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.32     |\n",
            "|    n_updates        | 5449     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 265      |\n",
            "|    ep_rew_mean      | -237     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 757      |\n",
            "|    time_elapsed     | 30       |\n",
            "|    total_timesteps  | 23334    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.869    |\n",
            "|    n_updates        | 5808     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 267      |\n",
            "|    ep_rew_mean      | -237     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 753      |\n",
            "|    time_elapsed     | 32       |\n",
            "|    total_timesteps  | 24523    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.809    |\n",
            "|    n_updates        | 6105     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 270      |\n",
            "|    ep_rew_mean      | -238     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 746      |\n",
            "|    time_elapsed     | 34       |\n",
            "|    total_timesteps  | 25949    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.12     |\n",
            "|    n_updates        | 6462     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 278      |\n",
            "|    ep_rew_mean      | -238     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 749      |\n",
            "|    time_elapsed     | 37       |\n",
            "|    total_timesteps  | 27849    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.746    |\n",
            "|    n_updates        | 6937     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 290      |\n",
            "|    ep_rew_mean      | -237     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 751      |\n",
            "|    time_elapsed     | 39       |\n",
            "|    total_timesteps  | 29468    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.912    |\n",
            "|    n_updates        | 7341     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 312      |\n",
            "|    ep_rew_mean      | -242     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 754      |\n",
            "|    time_elapsed     | 42       |\n",
            "|    total_timesteps  | 31898    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.05     |\n",
            "|    n_updates        | 7949     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 332      |\n",
            "|    ep_rew_mean      | -240     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 750      |\n",
            "|    time_elapsed     | 45       |\n",
            "|    total_timesteps  | 34243    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.737    |\n",
            "|    n_updates        | 8535     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 351      |\n",
            "|    ep_rew_mean      | -242     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 748      |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 36565    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.671    |\n",
            "|    n_updates        | 9116     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 363      |\n",
            "|    ep_rew_mean      | -241     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 750      |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 38211    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.627    |\n",
            "|    n_updates        | 9527     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 394      |\n",
            "|    ep_rew_mean      | -240     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 754      |\n",
            "|    time_elapsed     | 55       |\n",
            "|    total_timesteps  | 41737    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.991    |\n",
            "|    n_updates        | 10409    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 411      |\n",
            "|    ep_rew_mean      | -237     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 748      |\n",
            "|    time_elapsed     | 58       |\n",
            "|    total_timesteps  | 43970    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.818    |\n",
            "|    n_updates        | 10967    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 426      |\n",
            "|    ep_rew_mean      | -236     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 747      |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 45985    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.787    |\n",
            "|    n_updates        | 11471    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 435      |\n",
            "|    ep_rew_mean      | -233     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 63       |\n",
            "|    total_timesteps  | 47467    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 11841    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 446      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 745      |\n",
            "|    time_elapsed     | 66       |\n",
            "|    total_timesteps  | 49319    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.74     |\n",
            "|    n_updates        | 12304    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 458      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 747      |\n",
            "|    time_elapsed     | 68       |\n",
            "|    total_timesteps  | 51209    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.18     |\n",
            "|    n_updates        | 12777    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 479      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 742      |\n",
            "|    time_elapsed     | 72       |\n",
            "|    total_timesteps  | 53911    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.02     |\n",
            "|    n_updates        | 13452    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 491      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 743      |\n",
            "|    time_elapsed     | 75       |\n",
            "|    total_timesteps  | 55935    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.34     |\n",
            "|    n_updates        | 13958    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 498      |\n",
            "|    ep_rew_mean      | -214     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 78       |\n",
            "|    total_timesteps  | 58827    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.24     |\n",
            "|    n_updates        | 14681    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 501      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 82       |\n",
            "|    total_timesteps  | 61487    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.69     |\n",
            "|    n_updates        | 15346    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 500      |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 740      |\n",
            "|    time_elapsed     | 84       |\n",
            "|    total_timesteps  | 62846    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 15686    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 508      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 742      |\n",
            "|    time_elapsed     | 86       |\n",
            "|    total_timesteps  | 64387    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.959    |\n",
            "|    n_updates        | 16071    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 522      |\n",
            "|    ep_rew_mean      | -162     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 743      |\n",
            "|    time_elapsed     | 89       |\n",
            "|    total_timesteps  | 66402    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 16575    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 515      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 91       |\n",
            "|    total_timesteps  | 68257    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.972    |\n",
            "|    n_updates        | 17039    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 500      |\n",
            "|    ep_rew_mean      | -140     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 743      |\n",
            "|    time_elapsed     | 94       |\n",
            "|    total_timesteps  | 69893    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.15     |\n",
            "|    n_updates        | 17448    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 498      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 739      |\n",
            "|    time_elapsed     | 97       |\n",
            "|    total_timesteps  | 71739    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.627    |\n",
            "|    n_updates        | 17909    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 504      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 740      |\n",
            "|    time_elapsed     | 99       |\n",
            "|    total_timesteps  | 73708    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.76     |\n",
            "|    n_updates        | 18401    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 513      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 741      |\n",
            "|    time_elapsed     | 102      |\n",
            "|    total_timesteps  | 75791    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.702    |\n",
            "|    n_updates        | 18922    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 516      |\n",
            "|    ep_rew_mean      | -98.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 740      |\n",
            "|    time_elapsed     | 104      |\n",
            "|    total_timesteps  | 77555    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.26     |\n",
            "|    n_updates        | 19363    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 521      |\n",
            "|    ep_rew_mean      | -85.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 739      |\n",
            "|    time_elapsed     | 108      |\n",
            "|    total_timesteps  | 79906    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.58     |\n",
            "|    n_updates        | 19951    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 535      |\n",
            "|    ep_rew_mean      | -82.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 738      |\n",
            "|    time_elapsed     | 112      |\n",
            "|    total_timesteps  | 82943    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.895    |\n",
            "|    n_updates        | 20710    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 542      |\n",
            "|    ep_rew_mean      | -71.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 740      |\n",
            "|    time_elapsed     | 116      |\n",
            "|    total_timesteps  | 86133    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.3      |\n",
            "|    n_updates        | 21508    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 547      |\n",
            "|    ep_rew_mean      | -65.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 741      |\n",
            "|    time_elapsed     | 119      |\n",
            "|    total_timesteps  | 88901    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.82     |\n",
            "|    n_updates        | 22200    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 557      |\n",
            "|    ep_rew_mean      | -57.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 739      |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 92256    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.769    |\n",
            "|    n_updates        | 23038    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 575      |\n",
            "|    ep_rew_mean      | -47.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 741      |\n",
            "|    time_elapsed     | 129      |\n",
            "|    total_timesteps  | 95688    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.12     |\n",
            "|    n_updates        | 23896    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 580      |\n",
            "|    ep_rew_mean      | -43.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 737      |\n",
            "|    time_elapsed     | 135      |\n",
            "|    total_timesteps  | 99688    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.797    |\n",
            "|    n_updates        | 24896    |\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = DQN.load(\"dqn_lunar_lander\", env=env)\n",
        "\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Evaluate the agent\n",
        "# NOTE: If you use wrappers with your environment that modify rewards,\n",
        "#       this will be reflected here. To evaluate with original rewards,\n",
        "#       wrap environment in a \"Monitor\" wrapper before other wrappers.\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "\n",
        "# Enjoy trained agent\n",
        "vec_env = model.get_env()\n",
        "obs = vec_env.reset()\n",
        "for i in range(1000):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, rewards, dones, info = vec_env.step(action)\n",
        "    vec_env.render(\"rgb_array\")"
      ],
      "metadata": {
        "id": "3UCBkEhnNcG2",
        "outputId": "2b848b01-c5c7-4324-893b-20db93daeda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:233: UserWarning: Starting from gymnasium v0.26, render modes are determined during the initialization of the environment.\n",
            "                We allow to pass a mode argument to maintain a backwards compatible VecEnv API, but the mode (rgb_array)\n",
            "                has to be the same as the environment render mode (None) which is not the case.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3_fTwtoPlU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
